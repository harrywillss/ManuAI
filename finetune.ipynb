{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11438f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrywills/miniconda3/envs/ManuAI/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import os\n",
    "from datasets import DatasetDict\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification, TrainingArguments, Trainer, EarlyStoppingCallback, set_seed as t_set_seed, AutoConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio \n",
    "import torchaudio.transforms as T\n",
    "import numpy as np\n",
    "import json\n",
    "from datasets import Dataset, disable_caching\n",
    "import random\n",
    "from PIL import Image, ImageOps\n",
    "import evaluate\n",
    "from transformers import EvalPrediction\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report, precision_recall_curve\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil, os\n",
    "import librosa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea71ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed) \n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    t_set_seed(seed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e902d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Hugging Face datasets cache found.\n"
     ]
    }
   ],
   "source": [
    "# Clear Hugging Face datasets cache (memory issues)\n",
    "cache_dir = os.path.expanduser(\"~/.cache/huggingface/datasets\")\n",
    "if os.path.exists(cache_dir):\n",
    "    print(f\"Clearing Hugging Face datasets cache at {cache_dir} ...\")\n",
    "    shutil.rmtree(cache_dir)\n",
    "    print(\"Cache cleared.\")\n",
    "else:\n",
    "    print(\"No Hugging Face datasets cache found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d7ce97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size per class: 1500\n",
      "Using device: mps\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/site-packages/evaluate/loading.py:479\u001b[39m, in \u001b[36mHubEvaluationModuleFactory.get_module\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     local_path = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload_loading_script\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# if there is no file found with current revision tag try to load main\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/site-packages/evaluate/loading.py:469\u001b[39m, in \u001b[36mHubEvaluationModuleFactory.download_loading_script\u001b[39m\u001b[34m(self, revision)\u001b[39m\n\u001b[32m    468\u001b[39m     download_config.download_desc = \u001b[33m\"\u001b[39m\u001b[33mDownloading builder script\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/site-packages/evaluate/utils/file_utils.py:175\u001b[39m, in \u001b[36mcached_path\u001b[39m\u001b[34m(url_or_filename, download_config, **download_kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[32m    174\u001b[39m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output_path = \u001b[43mget_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_etag\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43muse_etag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdownload_desc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_desc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m os.path.exists(url_or_filename):\n\u001b[32m    189\u001b[39m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/site-packages/evaluate/utils/file_utils.py:511\u001b[39m, in \u001b[36mget_from_cache\u001b[39m\u001b[34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, token, download_desc)\u001b[39m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response.status_code == \u001b[32m404\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find file at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    512\u001b[39m _raise_if_offline_mode_is_enabled(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTried to reach \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Couldn't find file at https://huggingface.co/spaces/evaluate-metric/f1/resolve/v0.4.5/f1.py",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     58\u001b[39m precision_metric = evaluate.load(\u001b[33m\"\u001b[39m\u001b[33mprecision\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     59\u001b[39m recall_metric = evaluate.load(\u001b[33m\"\u001b[39m\u001b[33mrecall\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m f1_metric = \u001b[43mevaluate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mf1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/site-packages/evaluate/loading.py:748\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load a [`~evaluate.EvaluationModule`].\u001b[39;00m\n\u001b[32m    704\u001b[39m \n\u001b[32m    705\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    745\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    746\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    747\u001b[39m download_mode = DownloadMode(download_mode \u001b[38;5;129;01mor\u001b[39;00m DownloadMode.REUSE_DATASET_IF_EXISTS)\n\u001b[32m--> \u001b[39m\u001b[32m748\u001b[39m evaluation_module = \u001b[43mevaluation_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    749\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodule_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\n\u001b[32m    750\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m evaluation_cls = import_main_class(evaluation_module.module_path)\n\u001b[32m    752\u001b[39m evaluation_instance = evaluation_cls(\n\u001b[32m    753\u001b[39m     config_name=config_name,\n\u001b[32m    754\u001b[39m     process_id=process_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m    760\u001b[39m     **init_kwargs,\n\u001b[32m    761\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/site-packages/evaluate/loading.py:639\u001b[39m, in \u001b[36mevaluation_module_factory\u001b[39m\u001b[34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m current_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mmetric\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcomparison\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmeasurement\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    632\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    633\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHubEvaluationModuleFactory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mevaluate-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcurrent_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdynamic_modules_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdynamic_modules_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    640\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m    641\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/site-packages/evaluate/loading.py:484\u001b[39m, in \u001b[36mHubEvaluationModuleFactory.get_module\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    482\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.revision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m os.getenv(\u001b[33m\"\u001b[39m\u001b[33mHF_SCRIPTS_VERSION\u001b[39m\u001b[33m\"\u001b[39m, SCRIPTS_VERSION) != \u001b[33m\"\u001b[39m\u001b[33mmain\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    483\u001b[39m     revision = \u001b[33m\"\u001b[39m\u001b[33mmain\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m     local_path = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload_loading_script\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    486\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/site-packages/evaluate/loading.py:469\u001b[39m, in \u001b[36mHubEvaluationModuleFactory.download_loading_script\u001b[39m\u001b[34m(self, revision)\u001b[39m\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m download_config.download_desc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    468\u001b[39m     download_config.download_desc = \u001b[33m\"\u001b[39m\u001b[33mDownloading builder script\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/site-packages/evaluate/utils/file_utils.py:175\u001b[39m, in \u001b[36mcached_path\u001b[39m\u001b[34m(url_or_filename, download_config, **download_kwargs)\u001b[39m\n\u001b[32m    171\u001b[39m     url_or_filename = \u001b[38;5;28mstr\u001b[39m(url_or_filename)\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[32m    174\u001b[39m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output_path = \u001b[43mget_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_etag\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43muse_etag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdownload_desc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_desc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m os.path.exists(url_or_filename):\n\u001b[32m    189\u001b[39m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n\u001b[32m    190\u001b[39m     output_path = url_or_filename\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/site-packages/evaluate/utils/file_utils.py:457\u001b[39m, in \u001b[36mget_from_cache\u001b[39m\u001b[34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, local_files_only, use_etag, max_retries, token, download_desc)\u001b[39m\n\u001b[32m    455\u001b[39m     connected = ftp_head(url)\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m     response = \u001b[43mhttp_head\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m200\u001b[39m:  \u001b[38;5;66;03m# ok\u001b[39;00m\n\u001b[32m    466\u001b[39m         etag = response.headers.get(\u001b[33m\"\u001b[39m\u001b[33mETag\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m use_etag \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/site-packages/evaluate/utils/file_utils.py:378\u001b[39m, in \u001b[36mhttp_head\u001b[39m\u001b[34m(url, proxies, headers, cookies, allow_redirects, timeout, max_retries)\u001b[39m\n\u001b[32m    376\u001b[39m headers = copy.deepcopy(headers) \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    377\u001b[39m headers[\u001b[33m\"\u001b[39m\u001b[33muser-agent\u001b[39m\u001b[33m\"\u001b[39m] = get_datasets_user_agent(user_agent=headers.get(\u001b[33m\"\u001b[39m\u001b[33muser-agent\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m response = \u001b[43m_request_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/site-packages/evaluate/utils/file_utils.py:307\u001b[39m, in \u001b[36m_request_with_retry\u001b[39m\u001b[34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, **params)\u001b[39m\n\u001b[32m    305\u001b[39m tries += \u001b[32m1\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    308\u001b[39m     success = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (requests.exceptions.ConnectTimeout, requests.exceptions.ConnectionError) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/http/client.py:1395\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1393\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1394\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1395\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1396\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1397\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/http/client.py:325\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/http/client.py:286\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    288\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/socket.py:718\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m718\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    720\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/ssl.py:1314\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1311\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1312\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1313\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/ManuAI/lib/python3.11/ssl.py:1166\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# PARAMETERS\n",
    "training_size = int(input(\"Enter the amount of spectrograms per class to train on (0 for all): \")) # Number of spectrograms per class to use for training (0 for all)\n",
    "print(f\"Training size per class: {training_size if training_size > 0 else 'All available'}\")\n",
    "segments_path = \"./segments\"\n",
    "model_output_dir = \"./vit-base-manuai\" # Fine-tuned model output directory\n",
    "adapters_dir = \"./manuai_lora_adapters\" # LoRA adapters output directory\n",
    "checkpoints_dir = \"./manuai_checkpoints\" # Checkpoints output directory\n",
    "model_name = \"google/vit-base-patch16-224-in21k\"\n",
    "# Check if fine-tuned model already exists\n",
    "if os.path.exists(model_output_dir):\n",
    "    model_name = model_output_dir\n",
    "    print(\"Using existing fine-tuned model as base.\")\n",
    "\n",
    "processor = ViTImageProcessor.from_pretrained(model_name)\n",
    "sample_rate = 22050\n",
    "epochs = 25\n",
    "batch_size = 16\n",
    "n_proc = 3 # Number of processes for parallel processing\n",
    "dataloader_num_workers=2 # Number of workers for data loading (during training)\n",
    "seed = 42\n",
    "segment_len = 4.0\n",
    "lora_rank = 16\n",
    "image_size = 224  # ViT base model image size\n",
    "disable_caching() # Disable caching to avoid potential issues with large datasets\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=checkpoints_dir, \n",
    "    learning_rate=1e-4,  # 0.0001, 5e-5 = 0.00005, 3e-5 = 0.00003\n",
    "    lr_scheduler_type=\"cosine\", # \"linear\", \"cosine\"\n",
    "    warmup_ratio=0.1,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=epochs,\n",
    "    gradient_accumulation_steps=2, # To simulate larger batch size (batch_size * gradient_accumulation_steps)\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"steps\", # \"steps\" or \"epoch\"\n",
    "    eval_steps=500, # Only if eval_strategy=\"steps\"\n",
    "    save_strategy=\"steps\", # \"steps\" or \"epoch\"\n",
    "    save_steps=500, # Only if save_strategy=\"steps\"\n",
    "    load_best_model_at_end=True,\n",
    "    remove_unused_columns=False,\n",
    "    bf16=False,\n",
    "    logging_steps=100,\n",
    "    report_to=\"tensorboard\",\n",
    "    save_total_limit=3,\n",
    "    metric_for_best_model=\"eval_f1\",\n",
    "    greater_is_better=True,\n",
    "    #label_smoothing_factor=0.05, # Label smoothing factor\n",
    "    dataloader_pin_memory=False,\n",
    "    #max_grad_norm=1.0,\n",
    "    dataloader_num_workers=dataloader_num_workers,\n",
    ")\n",
    "set_seed(seed)\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "f1_metric = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548b3f6b",
   "metadata": {},
   "source": [
    "# Set up dataset\n",
    "Defines the labels\n",
    "Load all files\n",
    "Assign ID to labels\n",
    "Create dataset of `training_size` per specie, and augment if not enough samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c529ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_stretch_waveform(waveform, rate=1.1):\n",
    "    rate = random.uniform(0.8, 1.2) if rate is None else rate\n",
    "    waveform_np = waveform.squeeze().detach().cpu().numpy()\n",
    "    if waveform_np.ndim > 1:\n",
    "        waveform_np = waveform_np.mean(axis=0)  # Convert to mono\n",
    "    stretched = librosa.effects.time_stretch(y=waveform_np, rate=rate)\n",
    "    stretched_tensor = torch.tensor(stretched, dtype=waveform.dtype, device=waveform.device)\n",
    "    if stretched_tensor.ndim == 1:\n",
    "        stretched_tensor = stretched_tensor.unsqueeze(0)  # Ensure shape [1, time]\n",
    "    return stretched_tensor\n",
    "\n",
    "def augment_audio(sample, sample_rate, max_attempts=3):\n",
    "    sample = sample.to(device)\n",
    "    augmentations = [\n",
    "        lambda x: T.PitchShift(sample_rate, n_steps=random.choice([-2, -1, 1, 2])).to(device)(x), # Change pitch by -2, -1, +1, or +2 semitones\n",
    "        lambda x: x + torch.randn_like(x) * min(0.002, x.std().item() * 0.1), # Add Gaussian noise with stddev up to 10% of original signal's stddev, capped at 0.002\n",
    "        lambda x: T.FrequencyMasking(freq_mask_param=random.randint(8, 16)).to(device)(x), # Apply frequency masking with max width of 16 bins\n",
    "        lambda x: T.TimeMasking(time_mask_param=random.randint(8, 20)).to(device)(x), # Apply time masking with max width of 20 frames\n",
    "        lambda x: time_stretch_waveform(x), # Time-stretch by a random rate between 0.8 and 1.2\n",
    "    ]\n",
    "    \n",
    "    for attempt in range(max_attempts):\n",
    "        num_aug = random.randint(2, 3)  # Apply 2 to 3 augmentations\n",
    "        aug_funcs = random.sample(augmentations, num_aug)\n",
    "        augmented = sample.clone()  # Preserve original sample\n",
    "        \n",
    "        for augment in aug_funcs:\n",
    "            try:\n",
    "                temp_augmented = augment(augmented)\n",
    "                # Check if augmentation produces valid output\n",
    "                if is_valid_waveform(temp_augmented, min_variance=1e-8, min_amplitude=1e-4):\n",
    "                    augmented = temp_augmented\n",
    "                else:\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(f\"Augmentation error: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Final validation before returning\n",
    "        if is_valid_waveform(augmented, min_variance=1e-8, min_amplitude=1e-4):\n",
    "            return augmented\n",
    "        print(f\"Attempt {attempt + 1} failed: aug_var={augmented.var().item():.6f}, aug_max={augmented.abs().max().item():.6f}\")\n",
    "    \n",
    "    # If all attempts fail, return augmented sample\n",
    "    print(\"All augmentation attempts failed, returning augmented sample\")\n",
    "    return augmented\n",
    "\n",
    "def is_valid_waveform(waveform, min_variance=1e-8, min_amplitude=1e-4):\n",
    "    # If waveform is empty or has low variance, it's invalid\n",
    "    return waveform.abs().sum() > min_amplitude and waveform.var() > min_variance\n",
    "\n",
    "def load_audio_segments():\n",
    "    \"\"\"\n",
    "    Load exactly `training_size` samples per class.\n",
    "    Uses augmentation to fill the gap if there aren't enough originals.\n",
    "    \"\"\"\n",
    "    augmented_count = 0\n",
    "    files_labels = {label: [] for label in labels}\n",
    "    for root, dirs, files in os.walk(segments_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                label = os.path.splitext(file)[0].split('_')[1]\n",
    "                files_labels[label].append(os.path.join(root, file))\n",
    "    for label in labels:\n",
    "        print(f\"Found {len(files_labels[label])} files for label '{label}'\")\n",
    "        files = files_labels[label]\n",
    "\n",
    "        # Case 1: More files than training_size -> sample down\n",
    "        if training_size > 0 and len(files) > training_size:\n",
    "            selected_files = random.sample(files, training_size)\n",
    "        else:\n",
    "            selected_files = list(files)  # copy\n",
    "        samples = []\n",
    "\n",
    "        # Load original files\n",
    "        for file_path in selected_files:\n",
    "            waveform, sr = torchaudio.load(file_path)\n",
    "            if sr != sample_rate:\n",
    "                waveform = T.Resample(sr, sample_rate)(waveform)\n",
    "                sr = sample_rate\n",
    "\n",
    "            if not is_valid_waveform(waveform):\n",
    "                print(f\"Invalid original waveform for file: {file_path}\")\n",
    "                continue\n",
    "\n",
    "            samples.append({\n",
    "                \"audio\": {\"array\": waveform.squeeze().detach().cpu().numpy(), \"path\": file_path, \"sampling_rate\": sr},\n",
    "                \"label\": label_to_id[label]\n",
    "            })\n",
    "\n",
    "        # Case 2: If need to augment more samples to reach training_size\n",
    "        while len(samples) < training_size and len(selected_files) > 0:\n",
    "            f = random.choice(selected_files)\n",
    "            waveform, sr = torchaudio.load(f)\n",
    "            if sr != sample_rate:\n",
    "                waveform = T.Resample(sr, sample_rate)(waveform)\n",
    "                sr = sample_rate\n",
    "\n",
    "            if not is_valid_waveform(waveform):\n",
    "                continue\n",
    "\n",
    "            augmented = augment_audio(waveform, sr)\n",
    "            if not is_valid_waveform(augmented):\n",
    "                continue\n",
    "\n",
    "            augmented_count += 1\n",
    "            samples.append({\n",
    "                \"audio\": {\"array\": augmented.squeeze().detach().cpu().numpy(), \"path\": \"augmented.wav\", \"sampling_rate\": sr},\n",
    "                \"label\": label_to_id[label]\n",
    "            })\n",
    "\n",
    "        # Ensure exactly training_size (trim if overshot)\n",
    "        samples = samples[:training_size]\n",
    "\n",
    "        # Yield per-class samples\n",
    "        for s in samples:\n",
    "            yield s\n",
    "    print(f\"Total augmented samples created: {augmented_count}\")\n",
    "\n",
    "labels = sorted([d for d in os.listdir(segments_path) if not d.startswith('.')]) # Exclude hidden files\n",
    "label_to_id = {lbl: i for i, lbl in enumerate(labels)}\n",
    "id_to_label = {i: lbl for lbl, i in label_to_id.items()}\n",
    "\n",
    "dataset = Dataset.from_generator(load_audio_segments, cache_dir=None)\n",
    "\n",
    "print(\"Final label order:\", labels)\n",
    "\n",
    "if dataset:\n",
    "    print(f\"✅ Dataset created successfully with {len(dataset)} samples.\")\n",
    "else:\n",
    "    print(\"❌ Dataset creation failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d592604e",
   "metadata": {},
   "source": [
    "# Generate and plot spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2147ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_mel_spectrogram(sample, target_width=224, image_size=224):\n",
    "    \"\"\"\n",
    "    Convert audio sample to Mel spectrogram for ViT-based bird sound classification.\n",
    "    Ensures all images have consistent width for training.\n",
    "    \"\"\"\n",
    "    spectrogram_mode = \"delta3\" # Options: \"log-mel\", \"delta3\"\n",
    "    audio = sample[\"audio\"]\n",
    "    waveform = torch.tensor(audio[\"array\"], dtype=torch.float32)\n",
    "\n",
    "    if waveform.ndim == 1:\n",
    "        waveform = waveform.unsqueeze(0)\n",
    "\n",
    "    # Mel spectrogram\n",
    "    mel_spec_transform = T.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_fft=1024,\n",
    "        hop_length=256,\n",
    "        win_length=1024,\n",
    "        n_mels=128,\n",
    "        f_min=0,\n",
    "        f_max=11000,\n",
    "        power=2.0\n",
    "    )\n",
    "\n",
    "    mel_spec = mel_spec_transform(waveform).squeeze(0).numpy()\n",
    "    y_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "    # Process spectrogram channels\n",
    "    if spectrogram_mode == \"log-mel\":\n",
    "        y = np.clip(y_db, -80, 0)\n",
    "        y = ((y + 80) / 80 * 255).astype(np.uint8)\n",
    "        y = np.stack([y] * 3, axis=-1)\n",
    "    elif spectrogram_mode == \"delta3\":\n",
    "        delta1 = librosa.feature.delta(y_db)\n",
    "        delta2 = librosa.feature.delta(y_db, order=2)\n",
    "        y = np.stack([y_db, delta1, delta2], axis=-1)\n",
    "        y = ((y + 80) / 80 * 255).astype(np.uint8)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown spectrogram mode: {spectrogram_mode}\")\n",
    "\n",
    "    # Convert to PIL image\n",
    "    img = Image.fromarray(y).convert(\"RGB\")\n",
    "\n",
    "    # Resize height to target, scale width proportionally\n",
    "    h = img.height\n",
    "    w = img.width\n",
    "    new_h = image_size\n",
    "    new_w = int(w * (image_size / h))\n",
    "    img_resized = img.resize((new_w, new_h), Image.BICUBIC)\n",
    "\n",
    "    # Pad or crop width to target width\n",
    "    if new_w < target_width:\n",
    "        pad_left = (target_width - new_w) // 2\n",
    "        pad_right = target_width - new_w - pad_left\n",
    "        img_final = ImageOps.expand(img_resized, border=(pad_left, 0, pad_right, 0), fill=(0, 0, 0))\n",
    "    else:\n",
    "        # If width exceeds target, center crop\n",
    "        left = (new_w - target_width) // 2\n",
    "        img_final = img_resized.crop((left, 0, left + target_width, new_h))\n",
    "\n",
    "    sample[\"image\"] = img_final\n",
    "    sample[\"log_mel\"] = y_db\n",
    "    return sample\n",
    "\n",
    "def augment_spectrogram(spectrogram, time_mask_max=15, freq_mask_max=15, num_time_masks=2, num_freq_masks=2):\n",
    "    \"\"\"\n",
    "    Apply SpecAugment-style masking to a spectrogram.\n",
    "    \"\"\"\n",
    "    y = spectrogram.copy()\n",
    "    \n",
    "    H, W = y.shape[:2]\n",
    "    \n",
    "    # Apply frequency masks\n",
    "    for _ in range(num_freq_masks):\n",
    "        f = random.randint(0, freq_mask_max)\n",
    "        f0 = random.randint(0, max(H - f, 1))\n",
    "        if y.ndim == 2:\n",
    "            y[f0:f0+f, :] = 0\n",
    "        else:\n",
    "            y[f0:f0+f, :, :] = 0\n",
    "    \n",
    "    # Apply time masks\n",
    "    for _ in range(num_time_masks):\n",
    "        t = random.randint(0, time_mask_max)\n",
    "        t0 = random.randint(0, max(W - t, 1))\n",
    "        if y.ndim == 2:\n",
    "            y[:, t0:t0+t] = 0\n",
    "        else:\n",
    "            y[:, t0:t0+t, :] = 0\n",
    "    \n",
    "    return y\n",
    "\n",
    "def transform(sample):\n",
    "    \"\"\"\n",
    "    Convert PIL image to tensor using processor\n",
    "    \"\"\"\n",
    "    # Augment with random probability (Not currently needed)\n",
    "    if random.random() < 0.4:\n",
    "        sample[\"image\"] = Image.fromarray(augment_spectrogram(np.array(sample[\"image\"])))\n",
    "    inputs = processor(images=sample[\"image\"], return_tensors=\"pt\", do_normalize=True)\n",
    "    \n",
    "    # Remove batch dimension\n",
    "    sample[\"pixel_values\"] = inputs[\"pixel_values\"].squeeze(0)\n",
    "    return sample\n",
    "\n",
    "dataset = dataset.map(\n",
    "    convert_to_mel_spectrogram,\n",
    "    remove_columns=[\"audio\"],\n",
    "    num_proc=n_proc,\n",
    "    load_from_cache_file=False\n",
    ")\n",
    "\n",
    "dataset = dataset.map(\n",
    "    transform,\n",
    "    remove_columns=[\"image\"],\n",
    "    num_proc=n_proc,\n",
    "    load_from_cache_file=False\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(dataset)} mel spectrograms.\")\n",
    "print(dataset.features)\n",
    "print(\"\\nData ready for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bb3889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 9 random spectrograms and their labels\n",
    "if os.path.exists(\"spectrograms/\"):\n",
    "    print(f\"Directory spectrograms/ already exists. Deleting entire folder.\")\n",
    "    shutil.rmtree(\"spectrograms/\")\n",
    "os.makedirs(\"spectrograms/\")\n",
    "for plot_idx, i in enumerate(random.sample(range(len(dataset)), 9)):\n",
    "    y_vis = np.array(dataset[i][\"log_mel\"])\n",
    "    y_norm = (y_vis - y_vis.min()) / (y_vis.max() - y_vis.min())\n",
    "    #plt.figure(figsize=(15, 4))\n",
    "    plt.imshow(y_norm, aspect='auto', origin='lower')\n",
    "    plt.title(f\"Sample {i} - Label: {id_to_label[dataset[i]['label']]}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.colorbar()\n",
    "    plt.savefig(f\"spectrograms/sample_{id_to_label[dataset[i]['label']]}_{i}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b62f6cc",
   "metadata": {},
   "source": [
    "# Set up Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed40a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, test, and validation sets\n",
    "train_idx, temp_idx, train_labels, temp_labels = train_test_split(\n",
    "    np.arange(len(dataset)), labels, test_size=0.2, stratify=labels, random_state=seed\n",
    ")\n",
    "val_idx, test_idx, val_labels, test_labels = train_test_split(\n",
    "    temp_idx, temp_labels, test_size=0.5, stratify=temp_labels, random_state=seed\n",
    ")\n",
    "dataset = DatasetDict({\n",
    "    'train': dataset.select(train_idx),\n",
    "    'validation': dataset.select(val_idx),\n",
    "    'test': dataset.select(test_idx)\n",
    "})\n",
    "for split in ['train', 'validation', 'test']:\n",
    "    split_labels = dataset[split]['label']\n",
    "    class_counts = np.bincount(split_labels)\n",
    "    print(f\"{split} class distribution:\")\n",
    "    for i, count in enumerate(class_counts):\n",
    "        print(f\"  {id_to_label[i]}: {count} ({100 * count / len(split_labels):.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c13a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET UP MODEL\n",
    "def trainable_parameters(model):\n",
    "    params, trainable = 0, 0\n",
    "    \n",
    "    for _, p in model.named_parameters():\n",
    "        params += p.numel()\n",
    "        trainable += p.numel() if p.requires_grad else 0\n",
    "\n",
    "    return f\"{model.__class__.__name__} trainable parameters: {trainable:,}/{params:,} ({100 * trainable / params:.2f}%)\"\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        \"pixel_values\": torch.stack([torch.tensor(item[\"pixel_values\"]) for item in batch]).to(device),\n",
    "        \"labels\": torch.tensor([item[\"label\"] for item in batch], dtype=torch.long).to(device)\n",
    "    }\n",
    "\n",
    "def compute_metrics(eval_pred: EvalPrediction):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Overall metrics\n",
    "    acc = accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
    "    prec = precision_metric.compute(predictions=preds, references=labels, average=\"weighted\")[\"precision\"]\n",
    "    rec = recall_metric.compute(predictions=preds, references=labels, average=\"weighted\")[\"recall\"]\n",
    "    f1 = f1_metric.compute(predictions=preds, references=labels, average=\"weighted\")[\"f1\"]\n",
    "    auc = roc_auc_score(labels, torch.nn.functional.softmax(torch.tensor(logits), dim=-1).numpy(), multi_class='ovr', average='macro')\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "        \"auc\": auc\n",
    "    }\n",
    "\n",
    "def focal_loss(inputs, targets, alpha=1, gamma=2, reduction='mean', weight=None):\n",
    "    ce_loss = nn.CrossEntropyLoss(reduction='none', weight=weight, label_smoothing=training_args.label_smoothing_factor)(inputs, targets)\n",
    "    pt = torch.exp(-ce_loss)\n",
    "    focal_loss = alpha * (1 - pt) ** gamma * ce_loss\n",
    "\n",
    "    if reduction == 'mean':\n",
    "        return focal_loss.mean()\n",
    "    elif reduction == 'sum':\n",
    "        return focal_loss.sum()\n",
    "    else:\n",
    "        return focal_loss\n",
    "    \n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, class_weights=None, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)   \n",
    "        logits = outputs.get(\"logits\")\n",
    "        #loss_fn = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=training_args.label_smoothing_factor)\n",
    "        #loss = loss_fn(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        loss = focal_loss(logits, labels, gamma=2.0, alpha=0.25, weight=class_weights) # alt. Focal loss\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Model Architecture\n",
    "callbacks = [EarlyStoppingCallback(early_stopping_patience=4)]\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"google/vit-base-patch16-224-in21k\",\n",
    "    num_labels=len(labels),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id,\n",
    "    hidden_dropout_prob=0.1, # Dropout for fully connected layers\n",
    "    attention_probs_dropout_prob=0.1 # Dropout for attention layers\n",
    ")\n",
    "\n",
    "base_model = ViTForImageClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=len(labels),\n",
    "    id2label=id_to_label,\n",
    "    label2id=label_to_id\n",
    ")\n",
    "\n",
    "lora = LoraConfig(\n",
    "    r=lora_rank,\n",
    "    lora_alpha=lora_rank * 2,\n",
    "    lora_dropout=0.1, # Dropout for LoRA layer\n",
    "    bias=\"none\", # No bias adaptation\n",
    "    target_modules=[\"query\", \"key\", \"value\", \"dense\"], # Attention & MLP layers \n",
    "    modules_to_save=[\"classifier\"]\n",
    ")\n",
    "\n",
    "train_labels = dataset[\"train\"][\"label\"]\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "peft_model = get_peft_model(base_model, lora).to(device)\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor,\n",
    "    data_collator=collate_fn,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "print(f\"ID to label mapping: {id_to_label}\")\n",
    "print(trainable_parameters(peft_model))\n",
    "print(\"Model set-up complete. Ready to begin training...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c4e08a",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4303bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN MODEL\n",
    "result = trainer.train(resume_from_checkpoint=checkpoints_dir if os.path.exists(checkpoints_dir) else None)\n",
    "trainer.log_metrics(\"train\", result.metrics)\n",
    "trainer.save_metrics(\"train\", result.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367adb9e",
   "metadata": {},
   "source": [
    "# Evaluate & Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f32a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE ON TEST SET \n",
    "metrics = trainer.evaluate(eval_dataset=dataset[\"test\"])\n",
    "trainer.log_metrics(\"test\", metrics)\n",
    "trainer.save_metrics(\"test\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd65cba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model and processor\n",
    "base_model.save_pretrained(model_output_dir) # Saves full fine-tuned model (ViTForImageClassification.from_pretrained(\"./vit-base-manuai\"))\n",
    "processor.save_pretrained(model_output_dir) # Saves image processor (ViTImageProcessor.from_pretrained(\"./vit-base-manuai\"))\n",
    "print(f\"Model fine-tuned and saved to {model_output_dir}\")\n",
    "# Save LoRA adapters\n",
    "peft_model.save_pretrained(adapters_dir) # Saves only LoRA adapters (PEFTModel.from_pretrained(base_model, \"./manuai_lora_adapters\"))\n",
    "print(f\"LoRA adapters saved to {adapters_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9a70e2",
   "metadata": {},
   "source": [
    "# Show Metrics of fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac0d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL METRIC EVALUATION REPORT\n",
    "print(metrics)\n",
    "\n",
    "# Per-class\n",
    "predictions = trainer.predict(dataset[\"test\"])\n",
    "y_true = predictions.label_ids\n",
    "y_pred = np.argmax(predictions.predictions, axis=-1)\n",
    "logits = predictions.predictions  # shape (N, n_classes)\n",
    "probs = torch.nn.functional.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "\n",
    "accuracy_per_class = {}\n",
    "for i, label_name in enumerate(labels):\n",
    "    idx = (y_true == i) \n",
    "    accuracy_per_class[label_name] = (y_pred[idx] == y_true[idx]).mean()\n",
    "\n",
    "print(\"Accuracy per class:\")\n",
    "for label, acc in accuracy_per_class.items():\n",
    "    print(f\"{label}: {acc:.2f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "report = classification_report(y_true, y_pred, target_names=labels)\n",
    "print(report)\n",
    "\n",
    "# Confusion Matrix (plot)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(\"confusion_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75abe008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_thresholds(probs, thresholds):\n",
    "    preds = []\n",
    "    for p in probs:\n",
    "        # classes above their threshold\n",
    "        above = [i for i, th in enumerate(thresholds) if p[i] >= th]\n",
    "        if len(above) == 0:\n",
    "            preds.append(int(np.argmax(p)))  # fallback\n",
    "        elif len(above) == 1:\n",
    "            preds.append(int(above[0]))\n",
    "        else:\n",
    "            # multiple candidates: pick the one with highest prob among them\n",
    "            chosen = int(np.argmax(p[above]))\n",
    "            preds.append(above[chosen])\n",
    "    return np.array(preds)\n",
    "# Find optimal thresholds per class based on F1 score\n",
    "# Using precision-recall curve\n",
    "\n",
    "n_classes = probs.shape[1]\n",
    "best_thresholds = np.zeros(n_classes, dtype=float)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    y_true_i = (y_true == i).astype(int)\n",
    "    prob_i = probs[:, i]\n",
    "    # if no positives or all positives, set threshold 0.5\n",
    "    if y_true_i.sum() == 0 or y_true_i.sum() == len(y_true_i):\n",
    "        best_thresholds[i] = 0.5\n",
    "        continue\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true_i, prob_i)\n",
    "    # thresholds length = len(precision) - compute F1 for the threshold points\n",
    "    f1_scores = 2 * precision[:-1] * recall[:-1] / (precision[:-1] + recall[:-1] + 1e-12)\n",
    "    if np.isnan(f1_scores).all():\n",
    "        best_thresholds[i] = 0.5\n",
    "    else:\n",
    "        best_idx = np.nanargmax(f1_scores)\n",
    "        best_thresholds[i] = thresholds[best_idx]\n",
    "\n",
    "print(\"Best thresholds per class:\", {id_to_label[i]: float(best_thresholds[i]) for i in range(n_classes)})\n",
    "\n",
    "preds_thresh = apply_thresholds(probs, best_thresholds)\n",
    "# Present classification report\n",
    "thresh_report = classification_report(y_true, preds_thresh, target_names=labels)\n",
    "print(\"Classification Report of Model with Optimal Thresholds:\\n\", thresh_report)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6788801a",
   "metadata": {},
   "source": [
    "# ZIP model & training files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2d2ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather all relevant info\n",
    "training_info = {\n",
    "    \"hyperparameters\": {\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": training_args.learning_rate,\n",
    "        \"model_name\": model_name,\n",
    "        \"lora_rank\": lora_rank,\n",
    "        \"seed\": seed,\n",
    "        \"segment_len\": segment_len,\n",
    "        \"image_size\": image_size,\n",
    "        \"labels\": labels,\n",
    "    },\n",
    "    \"train_metrics\": result.metrics if 'result' in locals() else None,\n",
    "    \"eval_metrics\": metrics if 'metrics' in locals() else None,\n",
    "    \"per_class_accuracy\": accuracy_per_class if 'accuracy_per_class' in locals() else None,\n",
    "    \"classification_report\": report if 'report' in locals() else None,\n",
    "    \"best_thresholds\": {id_to_label[i]: float(best_thresholds[i]) for i in range(len(best_thresholds))} if 'best_thresholds' in locals() else None,\n",
    "}\n",
    "\n",
    "# Save as JSON\n",
    "with open(\"training_metrics.json\", \"w\") as f:\n",
    "    json.dump(training_info, f, indent=2)\n",
    "\n",
    "print(\"Saved all training info to training_metrics.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb70f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZIP MODEL & ADAPTERS\n",
    "import zipfile\n",
    "!zip -r manuai_models.zip vit-base-manuai manuai_lora_adapters training_metrics.json confusion_matrix.png\n",
    "print(\"Model, adapters, and training metrics zipped into manuai_models.zip\")\n",
    "\n",
    "with zipfile.ZipFile(\"manuai_models.zip\", 'r') as zf:\n",
    "    bad_file = zf.testzip()\n",
    "    if bad_file is not None:\n",
    "        print(f\"Corrupted file in zip: {bad_file}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ManuAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
